TASKS = {
    "mmlux_cs_all": ['mmlux_cs_abstract_algebra', 'mmlux_cs_anatomy', 'mmlux_cs_astronomy', 'mmlux_cs_business_ethics', 'mmlux_cs_clinical_knowledge', 'mmlux_cs_college_biology', 'mmlux_cs_college_chemistry', 'mmlux_cs_college_computer_science', 'mmlux_cs_college_mathematics', 'mmlux_cs_college_medicine', 'mmlux_cs_college_physics', 'mmlux_cs_computer_security', 'mmlux_cs_conceptual_physics', 'mmlux_cs_econometrics', 'mmlux_cs_electrical_engineering', 'mmlux_cs_elementary_mathematics', 'mmlux_cs_formal_logic', 'mmlux_cs_global_facts', 'mmlux_cs_high_school_biology', 'mmlux_cs_high_school_chemistry', 'mmlux_cs_high_school_computer_science', 'mmlux_cs_high_school_european_history', 'mmlux_cs_high_school_geography', 'mmlux_cs_high_school_government_and_politics', 'mmlux_cs_high_school_macroeconomics', 'mmlux_cs_high_school_mathematics', 'mmlux_cs_high_school_microeconomics', 'mmlux_cs_high_school_physics', 'mmlux_cs_high_school_psychology', 'mmlux_cs_high_school_statistics', 'mmlux_cs_high_school_us_history', 'mmlux_cs_high_school_world_history', 'mmlux_cs_human_aging', 'mmlux_cs_human_sexuality', 'mmlux_cs_international_law', 'mmlux_cs_jurisprudence', 'mmlux_cs_logical_fallacies', 'mmlux_cs_machine_learning', 'mmlux_cs_management', 'mmlux_cs_marketing', 'mmlux_cs_medical_genetics', 'mmlux_cs_miscellaneous', 'mmlux_cs_moral_disputes', 'mmlux_cs_moral_scenarios', 'mmlux_cs_nutrition', 'mmlux_cs_philosophy', 'mmlux_cs_prehistory', 'mmlux_cs_professional_accounting', 'mmlux_cs_professional_law', 'mmlux_cs_professional_medicine', 'mmlux_cs_professional_psychology', 'mmlux_cs_public_relations', 'mmlux_cs_security_studies', 'mmlux_cs_sociology', 'mmlux_cs_us_foreign_policy', 'mmlux_cs_virology', 'mmlux_cs_world_religions']
}
