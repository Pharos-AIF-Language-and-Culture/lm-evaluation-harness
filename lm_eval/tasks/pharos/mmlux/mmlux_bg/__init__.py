TASKS = {
    "mmlux_bg_all": ['mmlux_bg_abstract_algebra', 'mmlux_bg_anatomy', 'mmlux_bg_astronomy', 'mmlux_bg_business_ethics', 'mmlux_bg_clinical_knowledge', 'mmlux_bg_college_biology', 'mmlux_bg_college_chemistry', 'mmlux_bg_college_computer_science', 'mmlux_bg_college_mathematics', 'mmlux_bg_college_medicine', 'mmlux_bg_college_physics', 'mmlux_bg_computer_security', 'mmlux_bg_conceptual_physics', 'mmlux_bg_econometrics', 'mmlux_bg_electrical_engineering', 'mmlux_bg_elementary_mathematics', 'mmlux_bg_formal_logic', 'mmlux_bg_global_facts', 'mmlux_bg_high_school_biology', 'mmlux_bg_high_school_chemistry', 'mmlux_bg_high_school_computer_science', 'mmlux_bg_high_school_european_history', 'mmlux_bg_high_school_geography', 'mmlux_bg_high_school_government_and_politics', 'mmlux_bg_high_school_macroeconomics', 'mmlux_bg_high_school_mathematics', 'mmlux_bg_high_school_microeconomics', 'mmlux_bg_high_school_physics', 'mmlux_bg_high_school_psychology', 'mmlux_bg_high_school_statistics', 'mmlux_bg_high_school_us_history', 'mmlux_bg_high_school_world_history', 'mmlux_bg_human_aging', 'mmlux_bg_human_sexuality', 'mmlux_bg_international_law', 'mmlux_bg_jurisprudence', 'mmlux_bg_logical_fallacies', 'mmlux_bg_machine_learning', 'mmlux_bg_management', 'mmlux_bg_marketing', 'mmlux_bg_medical_genetics', 'mmlux_bg_miscellaneous', 'mmlux_bg_moral_disputes', 'mmlux_bg_moral_scenarios', 'mmlux_bg_nutrition', 'mmlux_bg_philosophy', 'mmlux_bg_prehistory', 'mmlux_bg_professional_accounting', 'mmlux_bg_professional_law', 'mmlux_bg_professional_medicine', 'mmlux_bg_professional_psychology', 'mmlux_bg_public_relations', 'mmlux_bg_security_studies', 'mmlux_bg_sociology', 'mmlux_bg_us_foreign_policy', 'mmlux_bg_virology', 'mmlux_bg_world_religions']
}
